{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d9875d6e-0e80-496d-8851-e998700254f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Could not fetch URL https://pypi.org/simple/pyspark/: There was a problem confirming the ssl certificate: HTTPSConnectionPool(host='pypi.org', port=443): Max retries exceeded with url: /simple/pyspark/ (Caused by SSLError(SSLEOFError(8, 'EOF occurred in violation of protocol (_ssl.c:1129)'))) - skipping\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Retrying (Retry(total=4, connect=None, read=None, redirect=None, status=None)) after connection broken by 'SSLError(SSLEOFError(8, 'EOF occurred in violation of protocol (_ssl.c:1129)'))': /simple/pyspark/\n",
      "WARNING: Retrying (Retry(total=3, connect=None, read=None, redirect=None, status=None)) after connection broken by 'SSLError(SSLEOFError(8, 'EOF occurred in violation of protocol (_ssl.c:1129)'))': /simple/pyspark/\n",
      "WARNING: Retrying (Retry(total=2, connect=None, read=None, redirect=None, status=None)) after connection broken by 'SSLError(SSLEOFError(8, 'EOF occurred in violation of protocol (_ssl.c:1129)'))': /simple/pyspark/\n",
      "WARNING: Retrying (Retry(total=1, connect=None, read=None, redirect=None, status=None)) after connection broken by 'SSLError(SSLEOFError(8, 'EOF occurred in violation of protocol (_ssl.c:1129)'))': /simple/pyspark/\n",
      "WARNING: Retrying (Retry(total=0, connect=None, read=None, redirect=None, status=None)) after connection broken by 'SSLError(SSLEOFError(8, 'EOF occurred in violation of protocol (_ssl.c:1129)'))': /simple/pyspark/\n",
      "ERROR: Could not find a version that satisfies the requirement pyspark (from versions: none)\n",
      "ERROR: No matching distribution found for pyspark\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: findspark in c:\\users\\nunnun\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.9_qbz5n2kfra8p0\\localcache\\local-packages\\python39\\site-packages (2.0.1)\n"
     ]
    }
   ],
   "source": [
    "!pip install pyspark\n",
    "!pip install findspark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "93d9c3e7-f77e-466c-bab5-59a7d96c02a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import findspark\n",
    "findspark.init()\n",
    "import pyspark\n",
    "from pyspark.sql import SparkSession"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5b79ec55-9e93-4381-a61d-7fa6f589c913",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "            <div>\n",
       "                <p><b>SparkSession - in-memory</b></p>\n",
       "                \n",
       "        <div>\n",
       "            <p><b>SparkContext</b></p>\n",
       "\n",
       "            <p><a href=\"http://DESKTOP-GC7B68S:4040\">Spark UI</a></p>\n",
       "\n",
       "            <dl>\n",
       "              <dt>Version</dt>\n",
       "                <dd><code>v3.5.0</code></dd>\n",
       "              <dt>Master</dt>\n",
       "                <dd><code>local</code></dd>\n",
       "              <dt>AppName</dt>\n",
       "                <dd><code>PREDICT_RATINGS_OF_GOOGLE_LOCAL_REVIEWS_IE212_O11_GROUP7</code></dd>\n",
       "            </dl>\n",
       "        </div>\n",
       "        \n",
       "            </div>\n",
       "        "
      ],
      "text/plain": [
       "<pyspark.sql.session.SparkSession at 0x16058a95070>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scala_version = '2.12'  # your scala version\n",
    "spark_version = '3.5.0' # your spark version\n",
    "packages = [\n",
    "    f'org.apache.spark:spark-sql-kafka-0-10_{scala_version}:{spark_version}',\n",
    "    'org.apache.kafka:kafka-clients:3.6.0' #your kafka version\n",
    "]\n",
    "spark = SparkSession.builder.master(\"local\").appName(\"PREDICT_RATINGS_OF_GOOGLE_LOCAL_REVIEWS_IE212_O11_GROUP7\").config(\"spark.jars.packages\", \",\".join(packages)).getOrCreate()\n",
    "spark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "529ba1e7-4a1a-48b8-8442-724554af66d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import from_json\n",
    "from pyspark.sql.types import StructType, StructField, StringType, DoubleType, IntegerType\n",
    "\n",
    "# Thông tin Kafka\n",
    "bootstrap_servers = 'localhost:9092'\n",
    "kafka_topic = 'PREDICT_RATINGS_OF_GOOGLE_LOCAL_REVIEWS_IE212_O11_GROUP7'\n",
    "\n",
    "# Định nghĩa schema cho dữ liệu\n",
    "schema = StructType([\n",
    "    StructField(\"rating\", DoubleType(), True),\n",
    "    StructField(\"reviewerName\", StringType(), True),\n",
    "    StructField(\"reviewText\", StringType(), True),\n",
    "    StructField(\"categories\", StringType(), True),  # Cần xác định loại dữ liệu thích hợp\n",
    "    StructField(\"gPlusPlaceId\", StringType(), True),\n",
    "    StructField(\"unixReviewTime\", IntegerType(), True),\n",
    "    StructField(\"reviewTime\", StringType(), True),\n",
    "    StructField(\"gPlusUserId\", StringType(), True)\n",
    "])\n",
    "\n",
    "# Tạo DataFrame để đọc dữ liệu từ Kafka topic\n",
    "kafka_stream_df = spark.readStream.format(\"kafka\") \\\n",
    "    .option(\"kafka.bootstrap.servers\", bootstrap_servers) \\\n",
    "    .option(\"subscribe\", kafka_topic) \\\n",
    "    .load()\n",
    "\n",
    "# Chuyển đổi giá trị từ JSON string sang struct với schema đã định nghĩa\n",
    "json_stream_df = kafka_stream_df.selectExpr(\"CAST(value AS STRING)\") \\\n",
    "    .select(from_json(\"value\", schema).alias(\"data\")) \\\n",
    "    .select(\"data.*\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1add07ab-3fdd-4aec-9b23-72e5af8b6a9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hiển thị dữ liệu nhận được từ Kafka topic\n",
    "query = json_stream_df.writeStream.outputMode(\"append\").format(\"console\").start()\n",
    "\n",
    "# Chờ cho quá trình stream khởi động\n",
    "query.awaitTermination()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
